{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGZVmvwTP1xu"
      },
      "source": [
        "IERG4160\n",
        "\n",
        "Lecture 10: Neural network training practice\n",
        "\n",
        "This is also the assignment 3. Please complete this colab and:\n",
        "\n",
        "* Download it as .ipynb file (click on file -> download -> download as .ipynb file)\n",
        "* Submit .ipynb file to blackboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35rSGPtARpim"
      },
      "source": [
        "**To get started:**\n",
        "\n",
        "1. Make a copy of this colab\n",
        "\n",
        "2. Please download images from this folder and upload them to your Google Dirve:\n",
        "\n",
        "https://drive.google.com/drive/folders/14SNI0FRWIZnIO7eFHAtKRJFHodxq0OU8?usp=drive_link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkayUh3SPoh4"
      },
      "source": [
        "**Disclaimer**\n",
        "\n",
        "This tutorial comes from\n",
        "\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "https://stackoverflow.com/questions/47432168/taking-subsets-of-a-pytorch-dataset\n",
        "\n",
        "https://blog.csdn.net/qq_39753950/article/details/125743543\n",
        "\n",
        "https://github.com/selva86/datasets/blob/master/BostonHousing.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E525w09gRjNj"
      },
      "source": [
        "**Preparation**\n",
        "\n",
        "Similar to assignment 1, please make a copy of the following folder to your own Google drive.\n",
        "\n",
        "https://drive.google.com/drive/folders/14SNI0FRWIZnIO7eFHAtKRJFHodxq0OU8?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLVn1GVzPY4f"
      },
      "source": [
        "# Section 0: Setup\n",
        "\n",
        "**Requirement**: No thing to complete in this section. However, you need to run all the blocks in this section to get your colab ready.\n",
        "\n",
        "If your job restarts, just rerun it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting Image\n",
            "  Downloading image-1.5.33.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from Image) (9.4.0)\n",
            "Collecting django (from Image)\n",
            "  Obtaining dependency information for django from https://files.pythonhosted.org/packages/9c/5b/eed82065c5d938b17c4b7304ab5ebe762c7a5a7eaa8a10ab35541580d79a/Django-5.0.3-py3-none-any.whl.metadata\n",
            "  Downloading Django-5.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from Image) (1.16.0)\n",
            "Collecting asgiref<4,>=3.7.0 (from django->Image)\n",
            "  Obtaining dependency information for asgiref<4,>=3.7.0 from https://files.pythonhosted.org/packages/9b/80/b9051a4a07ad231558fcd8ffc89232711b4e618c15cb7a392a17384bbeef/asgiref-3.7.2-py3-none-any.whl.metadata\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting sqlparse>=0.3.1 (from django->Image)\n",
            "  Obtaining dependency information for sqlparse>=0.3.1 from https://files.pythonhosted.org/packages/98/5a/66d7c9305baa9f11857f247d4ba761402cea75db6058ff850ed7128957b7/sqlparse-0.4.4-py3-none-any.whl.metadata\n",
            "  Downloading sqlparse-0.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: tzdata in c:\\programdata\\anaconda3\\lib\\site-packages (from django->Image) (2023.3)\n",
            "Downloading Django-5.0.3-py3-none-any.whl (8.2 MB)\n",
            "   ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/8.2 MB 653.6 kB/s eta 0:00:13\n",
            "    --------------------------------------- 0.2/8.2 MB 1.5 MB/s eta 0:00:06\n",
            "   ------------------- -------------------- 3.9/8.2 MB 24.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 7.9/8.2 MB 41.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  8.2/8.2 MB 43.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.2/8.2 MB 32.7 MB/s eta 0:00:00\n",
            "Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
            "   ---------------------------------------- 0.0/41.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 41.2/41.2 kB ? eta 0:00:00\n",
            "Building wheels for collected packages: Image\n",
            "  Building wheel for Image (setup.py): started\n",
            "  Building wheel for Image (setup.py): finished with status 'done'\n",
            "  Created wheel for Image: filename=image-1.5.33-py2.py3-none-any.whl size=19489 sha256=64d2eeb4e6c82ab3c0d7ec09b74feba863961e347e2cc4298d5e38024a7f12f7\n",
            "  Stored in directory: c:\\users\\s1155158397\\appdata\\local\\pip\\cache\\wheels\\62\\40\\4f\\3c9a8d0f22a1a6f966975a460e5cb509a1e7dc42e2ce5d9a6d\n",
            "Successfully built Image\n",
            "Installing collected packages: sqlparse, asgiref, django, Image\n",
            "Successfully installed Image-1.5.33 asgiref-3.7.2 django-5.0.3 sqlparse-0.4.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script sqlformat.exe is installed in 'C:\\Users\\s1155158397\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script django-admin.exe is installed in 'C:\\Users\\s1155158397\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        }
      ],
      "source": [
        "!pip install Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "23762df2"
      },
      "outputs": [],
      "source": [
        "#@title Import all necessary libraries\n",
        "\n",
        "# General python library\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "# Torch library\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Colab\n",
        "# from google.colab import drive\n",
        "# I do it locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "xORFfNdrQ8ro"
      },
      "outputs": [],
      "source": [
        "#@title Useful functions\n",
        "\n",
        "def load_image(filename):\n",
        "  im_pil = Image.open(os.path.join(srcpath, filename))\n",
        "  im = np.array(im_pil).astype(np.float32) / 255\n",
        "  return im\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z51A9d1ZS2X9"
      },
      "source": [
        "**Note:** Update the `srcpath` below to the right path on your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TQoEs-jR_Gy",
        "outputId": "c7c88177-7841-4212-b132-01415e95b9a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "srcpath =  ierg_4190_in_class_lab/\n"
          ]
        }
      ],
      "source": [
        "#@title At last, mount your colab\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "#srcpath = 'C:/Users/s1155158397/Desktop/IERG4160 Lab/ierg_4190_in_class_lab'  #@param {type:'string'}\n",
        "#srcpath = os.path.join('/content/drive/My Drive', srcpath)\n",
        "srcpath = os.path.join('ierg_4190_in_class_lab/')\n",
        "print('srcpath = ', srcpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAOTY1S9QM-g"
      },
      "source": [
        "# Section 1: Tutorial for basic python operations\n",
        "\n",
        "**Requirement**: No thing to complete in this section. This is just some examples to teach you how to use python, numpy, and torch.\n",
        "\n",
        "We would also suggest to you read tutorial 1 carefully.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEnVcj-cXJqb"
      },
      "source": [
        "Operate numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwjPiv8qXGyU",
        "outputId": "66b2f2d3-9e25-4041-aab4-ffc70bd2f8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######\n",
            "a = \n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 0. 1.]\n",
            " [1. 1. 1. 1.]]\n",
            "######\n",
            "a.shape = \n",
            "(3, 4)\n"
          ]
        }
      ],
      "source": [
        "# Create an array\n",
        "a = np.ones((3, 4), np.float32)  # Create 3x4, float32 array\n",
        "\n",
        "# Modify an array\n",
        "a[1, 2] = 0\n",
        "\n",
        "# Print an array\n",
        "print('######')\n",
        "print('a = ')\n",
        "print(a)\n",
        "\n",
        "# Print array size\n",
        "print('######')\n",
        "print('a.shape = ')\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNHSMNwCXfxH"
      },
      "source": [
        "Operate torch tensor (array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iodevCFbXfWa",
        "outputId": "7815103e-0800-4128-8ec2-d765851a43b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######\n",
            "a = \n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "######\n",
            "a.shape = \n",
            "torch.Size([3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Create an array\n",
        "a = torch.ones((3, 4), dtype=torch.float32)  # Create 3x4, float32 array\n",
        "\n",
        "# Print an array\n",
        "print('######')\n",
        "print('a = ')\n",
        "print(a)\n",
        "\n",
        "# Print array size\n",
        "print('######')\n",
        "print('a.shape = ')\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9OKdwbqX2q7"
      },
      "source": [
        "Load and visualize an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "00CJw2hnX5EN",
        "outputId": "c4e8041e-8c2c-4e32-a9e6-01402557c123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####\n",
            "im.shape = (height, width, height)\n",
            "(512, 512, 3)\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Load image lenna\n",
        "im = load_image('lenna.jpg')\n",
        "\n",
        "# Print image size\n",
        "print('#####')\n",
        "print('im.shape = (height, width, height)')\n",
        "print(im.shape)\n",
        "\n",
        "# Visualize image lenna\n",
        "_ = plt.imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djk6DuE7Y90a"
      },
      "source": [
        "Visualize multiple images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "b4mFLMtfY9Tg",
        "outputId": "2900a7ff-603f-4bd7-eea1-cbb5c63c04c7"
      },
      "outputs": [],
      "source": [
        "# Create a figure with size 16x6\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# plt.subplot(1, 3, 1) means that we will create 1x3 sub figures and next we will show the 1st sub figure.\n",
        "plt.subplot(1, 3, 1); plt.imshow(im[..., 0], cmap='gray'); plt.title('Red')\n",
        "\n",
        "# plt.subplot(1, 3, 2) means that we will use 1x3 sub figures and next we will show the 2nd sub figure.\n",
        "plt.subplot(1, 3, 2); plt.imshow(im[..., 1], cmap='gray'); plt.title('Green')\n",
        "\n",
        "# 3rd sub figure.\n",
        "plt.subplot(1, 3, 3); plt.imshow(im[..., 2], cmap='gray'); plt.title('Blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcDtqa0GVpnN"
      },
      "source": [
        "# Section 2: Prepare dataset for training\n",
        "\n",
        "**Requirement**: No thing to complete in this section. However, if you need to run section 3 and 4, you need to run this blocks first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stT5_EWxbnu1"
      },
      "source": [
        "Recall that to train a network, we need:\n",
        "\n",
        "* **Networks**. Network contains unknown parameters.\n",
        "* **Dataset**. It includes both:\n",
        "  + A training set: on this dataset, we optimize the network parameters, which is called training.\n",
        "  + a test set: on this dataset, we evaluate whether performance of the network.\n",
        "* **Loss function**. A evaluation metric (loss) we want to minimize.\n",
        "* **Optimization method**. A method to minimize the loss function.\n",
        "\n",
        "Let us define: **dataset** and **loss** this section. **network** and **loss** will be defined in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0mu97ERocB4"
      },
      "source": [
        "## 2.1. Load the **dataset**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ_FOgVuo1iN"
      },
      "source": [
        "Here we use MNIST dataset, which is a digital recognition dataset. If you want to know more details, please check:\n",
        "\n",
        "https://en.wikipedia.org/wiki/MNIST_database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTtmF0p2StR_"
      },
      "source": [
        "This block may take about 10-20 seconds to download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6vbAZYdV8nG",
        "outputId": "872a0a35-3bde-45b0-f4d3-31c355bce4d8"
      },
      "outputs": [],
      "source": [
        "#@title Load the MNIST dataset\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Create data loaders.\n",
        "batch_size = 64    #@param {type:\"integer\"}\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUPZBAC3sA9w"
      },
      "source": [
        "Let us check how the shape of input and output. The input is 28x28 single channel image. The output is a single class label, whose value is 0-9 (10 possible values)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1iGzWZRRXUb"
      },
      "source": [
        "Each time we load an image, we actually load a batch, and first dimension is the batch size. Please refer to Lecture Note 7, Slide 69 for the definition of a batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbYcpCQ8r3Vd",
        "outputId": "dc8124ee-621d-4ff7-cd35-4a3dbc978f50"
      },
      "outputs": [],
      "source": [
        "#@title Print shapes of the input image and the output label\n",
        "\n",
        "# Note that this channel order in torch is slightly different from slides.\n",
        "\n",
        "for input_image, _ in test_dataloader:\n",
        "    print(f\"Shape of input image: [Number of images in a batch, No. of channel, Height, Width]: {input_image.shape}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "Iocdtqq5ytfZ",
        "outputId": "1a6055c8-86ae-4e3a-d2f4-eac1e1fd657c"
      },
      "outputs": [],
      "source": [
        "#@title Visualize the training 10 samples\n",
        "\n",
        "plt.figure(figsize=(40, 10))\n",
        "for input_image, ground_truth_label in test_dataloader:\n",
        "  for i in range(10):\n",
        "      plt.subplot(2, 5, i + 1)\n",
        "      plt.imshow(input_image[i, 0, ...], cmap='gray')\n",
        "      label_i = int(ground_truth_label[i])\n",
        "      plt.title(f'Number {ground_truth_label}', fontsize=18)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN31_Ng0pNC6"
      },
      "source": [
        "## 2.2. Define **loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtlEWDwtbdFo"
      },
      "outputs": [],
      "source": [
        "#@title Define **loss**\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wip890FZvr1"
      },
      "outputs": [],
      "source": [
        "#@title Also setup a training device.\n",
        "\n",
        "device = 'cpu'  # For this tutorial, cpu is enough. For more efficient training, you could GPU ('cuda'). However, you need to purchase GPU hours if you want to do so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQvafD3oqE9n"
      },
      "source": [
        "# Section 3: Define network and run training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unP6pzZYqar8"
      },
      "source": [
        "**Requirement**: Please run 3.1-3.3 and fill missing code in 3.4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdqOKEmFqx7L"
      },
      "source": [
        "**Note, please pay special attention to the block we highlighted below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32Ppyk1NZtQe"
      },
      "outputs": [],
      "source": [
        "#@title 3.1. Define the network\n",
        "\n",
        "class NeuralNetwork1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #################################################################\n",
        "        ### This block is very important. Make sure you understand it ###\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Flatten(),             # This flatten image, which converts 28x28 image to 756 vector\n",
        "            nn.Linear(28*28, 128),    # nn.Linear(a, b) means the input is a channels and the output is b chnnals\n",
        "            nn.Linear(128, 128),      # Similarly, this is 128-channel input and 128-channel output.\n",
        "            nn.Linear(128, 10)        # Since the output is 10-class, so the output must be 10 channels.\n",
        "        )\n",
        "        #################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsNZoICqq9m3"
      },
      "outputs": [],
      "source": [
        "#@title 3.2. Define the optimizer\n",
        "\n",
        "model_1 = NeuralNetwork1().to(device)\n",
        "learning_rate = 1e-1          # Check Lecture note 7, Slide 63 for the definition of learning rate\n",
        "optimizer = torch.optim.SGD(model_1.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCh_J15srp_K"
      },
      "source": [
        "**Please run the 3.3, and check the result.** It may take up to 30 seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj8fJz_ZZbLg"
      },
      "outputs": [],
      "source": [
        "#@title 3.3. Finally, we can run training.\n",
        "\n",
        "# For each epoch, we first run training to update the parameters, and run test to check the accuracy\n",
        "# Please refer to Lecture Note 7, slide 74 for details of `epoch`.\n",
        "\n",
        "epochs = 1\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model_1, loss_fn, optimizer)\n",
        "    test(test_dataloader, model_1, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2IHVKA21gts"
      },
      "source": [
        "The accuracy should be about 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiHt8h-RyFRp"
      },
      "source": [
        "**Please run missing code in 3.4, and check the result.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKgsl7Fwuobh"
      },
      "outputs": [],
      "source": [
        "#@title 3.4. Please fill this one. Run **another** 2 epochs.\n",
        "\n",
        "# Your code goes here\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQyn6lXL1TEQ"
      },
      "source": [
        "The accuracy should not change too much in these 2 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHaSEE8tvvgq"
      },
      "source": [
        "# Section 4. Update network structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abvawNmBwDK8"
      },
      "source": [
        "**Requirement**: Please complete the section 4.1 and run 4.2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfUZv0tYv3Sl"
      },
      "source": [
        "If you check closely, you may find that it miss some ReLU in the previous definition. Please try fix that in 4.1.\n",
        "\n",
        "**Hint:** Please check the Lecture Note 7, slide 38.\n",
        "\n",
        "**Hint:** The ReLU layer is defined as nn.ReLU(). For example, if you want to add a ReLU layer to first two linear layers, it looks like:\n",
        "\n",
        "nn.Sequential(\n",
        "...,\n",
        "nn.Linear(28*28, 128),\n",
        "nn.ReLU(),\n",
        "nn.Linear(128, 128),\n",
        "...\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gm2z6JQv25h"
      },
      "outputs": [],
      "source": [
        "#@title 4.1. Define the network.\n",
        "\n",
        "class NeuralNetwork2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #################################################################\n",
        "        # Your code goes here.\n",
        "        #################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp-Xy-YTwVN-"
      },
      "outputs": [],
      "source": [
        "#@title 4.2. Run training\n",
        "\n",
        "model_2 = NeuralNetwork2().to(device)\n",
        "learning_rate = 1e-1\n",
        "optimizer = torch.optim.SGD(model_2.parameters(), lr=learning_rate)\n",
        "epochs = 3\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model_2, loss_fn, optimizer)\n",
        "    test(test_dataloader, model_2, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFbzaxPXwV9o"
      },
      "source": [
        "**Note:** After run training, the test accuracy should be >95%. If it is much lower, it means that your code may have some issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzK0Yue21z0o"
      },
      "source": [
        "# Section 5. Run the trained network on a new image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYxXGfZBBJoz"
      },
      "source": [
        "**Requirement**: Please complete the section 5.3 and 5.4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxRnDWJ04wsN"
      },
      "source": [
        "## 5.1 Load a testing image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "L_3D1Thr4y5j",
        "outputId": "bca935b3-e87c-4c41-b552-59f14152d864"
      },
      "outputs": [],
      "source": [
        "test_image = 1.0 - cv2.cvtColor(load_image('2.jpg'), cv2.COLOR_RGB2GRAY)\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "print(test_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRCGWNmP5WvK"
      },
      "source": [
        "## 5.2 Run the trained network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXAuvks818f5",
        "outputId": "c7dbb432-9197-4e47-ec72-9811442bfbff"
      },
      "outputs": [],
      "source": [
        "test_image_torch = torch.Tensor(test_image[np.newaxis, np.newaxis])\n",
        "model_2.eval()\n",
        "predicted_torch = model_2(test_image_torch)\n",
        "predicted = predicted_torch.detach().numpy()[0, ...]\n",
        "print('The predicted label is:', predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE_ciCQO5k-y"
      },
      "source": [
        "## 5.3 Convert predicted one-hot vector to actual label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9aQVlDX5seN"
      },
      "outputs": [],
      "source": [
        "label =  # Your code goes here\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVv4QeB_5s9X"
      },
      "source": [
        "## 5.4 [Bonus] Try it on your own image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8IbO_Kj5zOp"
      },
      "source": [
        "Draw an hard-written digit using Windows paint, or other drawing software, upload this image to Google drive, and test the trained network.\n",
        "\n",
        "To finish that, please use plt.imshow to show your testing image, and also print the final result.\n",
        "\n",
        "If your image is not 28x28, try to use cv.resize to change the resolution.\n",
        "\n",
        "You may need to repeat 5.1-5.3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS923Wyy6FjH"
      },
      "outputs": [],
      "source": [
        "### Your code goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluWXKES6_9U"
      },
      "source": [
        "# Section 6. Try CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpPbRWu57GoW"
      },
      "source": [
        "## 6.1. Define network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvI6Uj_FAvsE"
      },
      "source": [
        "**Requirement**: Please fix an error in 6.1 and run 6.2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xxXvTSY87p-"
      },
      "source": [
        "Here we deliberately make in the highlighted line below. Please try to fix it.\n",
        "\n",
        "**Hint:** Try to calculate the image resolution by filling ? in the comment may help you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooEQWWIs7DJq"
      },
      "outputs": [],
      "source": [
        "#@title Define network\n",
        "\n",
        "class NeuralNetwork3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "                                                 # A convolutional network\n",
        "                                                 # After this layer, the image is 28x28 with 32 channels\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),                  # nn.MaxPool2d(2, 2) is a 2x2 pooling layer\n",
        "                                                 # After this layer, the image is 14x14 with 32 channels\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
        "                                                 # After this layer, the image is still 14x14 with 32 channels\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),                  # After this layer, the image is ?x? with 32 channels\n",
        "            nn.Flatten(),\n",
        "        #################################################################\n",
        "        # This line has a bug, please fix it.\n",
        "            nn.Linear(14*14*32, 10)   # Here we assume that input is 14x14 image with 32 channel, but this is actually wrong. Please fix it.\n",
        "        #################################################################\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVgjAUAd7_Kk"
      },
      "source": [
        "## 6.2 Run training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgWJw1z8UZ7i"
      },
      "source": [
        "This training is slower. May take 1-3 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue0dDJpK76Be"
      },
      "outputs": [],
      "source": [
        "#@title Run training\n",
        "\n",
        "model_3 = NeuralNetwork3().to(device)\n",
        "learning_rate = 1e-1\n",
        "optimizer = torch.optim.SGD(model_3.parameters(), lr=learning_rate)\n",
        "epochs = 3\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model_3, loss_fn, optimizer)\n",
        "    test(test_dataloader, model_3, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r42em6Q6AJ2r"
      },
      "source": [
        "If your code is correct, the accuracy should be >97%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw4GBNbDWm40"
      },
      "source": [
        "## 6.3 [bonus] Visualize intermediate layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e-lpL3zW30b"
      },
      "source": [
        "First, let us visualize the network. Note that there 8 layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsQboam1W52j"
      },
      "outputs": [],
      "source": [
        "print(model_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E3immeEWvTn"
      },
      "source": [
        "Let us run testing on an image. This time, we manually run each layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehd-6J8jUIb6",
        "outputId": "089cf01f-b3cf-466a-cf72-a49bdcdc3e1c"
      },
      "outputs": [],
      "source": [
        "test_image = 1.0 - cv2.cvtColor(load_image('2.jpg'), cv2.COLOR_RGB2GRAY)\n",
        "test_image_torch = torch.Tensor(test_image[np.newaxis, np.newaxis])\n",
        "layer_output = test_image_torch\n",
        "\n",
        "model_3.eval()\n",
        "for i in range(8):\n",
        "  layer_output = model_3.network[i](layer_output)\n",
        "print(layer_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X5ZO5hPXPnc"
      },
      "source": [
        "**Question**:  Visualize the first 4-channels of the 1st convolutional layer. You may need to change the block above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZgR-NwCUkoG"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n",
        "\n",
        "plt.figure(figsize=(16, 4))\n",
        "plt.subplot(1, 4, 1); plt.imshow()\n",
        "plt.subplot(1, 4, 2); plt.imshow()\n",
        "plt.subplot(1, 4, 3); plt.imshow()\n",
        "plt.subplot(1, 4, 4); plt.imshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrHV1GBXmQJ"
      },
      "source": [
        "**Question**:  Visualize the first 4-channels of the 2nd convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt6cwCZiXl5J"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AAOTY1S9QM-g"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
